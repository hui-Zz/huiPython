# -*- coding:utf-8 -*-
import os
import re
import sys
import time
import json
import base64
import datetime
import requests
import pymysql
import PyRSS2Gen
from configparser import ConfigParser
from lxml import etree
from threading import Thread
from curses.ascii import isdigit

# å•çº¿ç¨‹ï¼Œå¤šçº¿ç¨‹é‡‡é›†æ–¹å¼é€‰æ‹©(å¤šçº¿ç¨‹é‡‡é›†é€Ÿåº¦å¿«ä½†æœºå™¨è´Ÿè½½çŸ­æ—¶é«˜)
# thread = 'multi'
thread = 'single'

# é‡‡é›†æ•°æ®ä¿å­˜ç›®å½•,ä¸ºäº†å®‰å…¨è¯·ä¿®æ”¹æœ¬ç¨‹åºåå­—,æˆ–ç§»åŠ¨åˆ°å…¶ä»–ç›®å½•,å¹¶ä¿®æ”¹ä»¥ä¸‹è·¯å¾„,é»˜è®¤ä¸ç¨‹åºåŒç›®å½•
dir = os.path.dirname(os.path.abspath(__file__)) + "/json/"


def parse_weibo(db):
    # å¾®åšçƒ­ç‚¹æ’è¡Œæ¦œ
    try:
        url = 'https://s.weibo.com/top/summary?cate=realtimehot'
        hearders = {
            'User-Agent': '',
            'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',
            'accept-encoding': 'gzip, deflate, br',
            'accept-language': 'zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7',
            'cache-control': 'max-age=0',
            'cookie': '',
            'referer': 'https://passport.weibo.com/'
        }
        hotTxt = requests.get(url, headers=hearders).content.decode()
        newHotTxt = hotTxt.replace('\n', '')
        newHotTxt = newHotTxt.replace(" ", "")
        noTdTxt = re.findall("<tbody>(.*?)</tbody>", newHotTxt)[0]
        arrayTxt = re.findall('ranktop">(.*?)<tdclass="td-03">', noTdTxt)

        # ä¿å­˜æ•°æ®
        for x in range(5):
            try:
                ft = arrayTxt[x]
                # rank = arrayTxt[0:x.rfind("</")] #çƒ­æœæ’å
                urlTxt = ft.split('"') #çƒ­æœé“¾æ¥
                hotName = ft.split(">")  # çƒ­æœåç§°
                title = re.sub(r'</a', "", hotName[3])
                span = re.sub(r'</span', "", hotName[5])
                label = re.sub(r'\d|\s', "", span)
                if label=='ç»¼è‰º' or label=='å‰§é›†' or label=='ç”µå½±' or label=='éŸ³ä¹':
                    continue
                hot = re.sub(r'\D', "", span)
                emojis = re.findall(r"<imgsrc=\"(.+?)\"",ft)
                emoji = emojis[0] if emojis else ''
                contents = re.findall(r"title=\"(.+?)\"",ft)
                content = contents[0] if contents else ''
                result = []
                result.append(
                    ('å¾®åš', str(x + 1), title, 'https://s.weibo.com/' + urlTxt[3], emoji, hot, label, content))
                # print(result)
                inesrt_re = "insert ignore into huinews (source,rank,title,link,cover,hot,label,content) values (%s, %s, %s, %s, %s, %s, %s, %s)"
                cursor = db.cursor()
                cursor.executemany(inesrt_re, result)
                db.commit()
            except Exception as e:
                db.rollback()
                print(str(e))
                break
        # æŸ¥è¯¢è¾“å‡º
        rssItems=db_query("å¾®åš")
        makeRss("å¾®åšçƒ­æœ", url, "å¾®åšçƒ­ç‚¹æ’è¡Œæ¦œ", rssItems)
    except Exception as e:
        print(sys._getframe().f_code.co_name+"é‡‡é›†é”™è¯¯ï¼Œè¯·åŠæ—¶æ›´æ–°è§„åˆ™ï¼" + str(e))


def parse_baidu(db):
    # ç™¾åº¦çƒ­æœ
    try:
        url = 'https://top.baidu.com/board?platform=pc&sa=pcindex_a_right'
        hearders = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.4997.0 Safari/537.36'
        }
        res = requests.get(url, headers=hearders)
        html = etree.HTML(res.content.decode())
        data = html.xpath(
            '//*[@id="sanRoot"]/main/div[1]/div[1]/div[2]/a[*]/div[2]/div[2]/div/div/text()')
        linkList = html.xpath('//*[@id="sanRoot"]/main/div[1]/div[1]/div[2]/a/@href')
        coverList = html.xpath('//div[@class="active-item_1Em2h"]/img/@src')

        # ä¿å­˜æ•°æ®
        for i, title in enumerate(data):
            try:
                if i > 5:
                    break
                title = title.strip()
                result = []
                result.append(
                    ('ç™¾åº¦', i, title, linkList[i], coverList[i]))
                # print(result)
                inesrt_re = "insert ignore into huinews (source,rank,title,link,cover) values (%s, %s, %s, %s, %s)"
                cursor = db.cursor()
                cursor.executemany(inesrt_re, result)
                db.commit()
            except Exception as e:
                db.rollback()
                print(str(e))
                break
        # æŸ¥è¯¢è¾“å‡º
        rssItems=db_query("ç™¾åº¦")
        makeRss("ç™¾åº¦çƒ­æœ", url, "ç™¾åº¦çƒ­æœé£äº‘æ¦œ", rssItems)
    except Exception as e:
        print(sys._getframe().f_code.co_name+"é‡‡é›†é”™è¯¯ï¼Œè¯·åŠæ—¶æ›´æ–°è§„åˆ™ï¼" + str(e))

# ã€çŸ¥ä¹çƒ­æœã€‘
def parse_zhihu(db):
    try:
        url = 'https://www.zhihu.com/api/v3/feed/topstory/hot-lists/total?limit=50&desktop=true'
        headers = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) '
                                'Chrome/86.0.4240.198 Safari/537.36'}
        allResponse = requests.get(url, headers=headers).text
        jsonDecode = json.loads(allResponse)
        # ä¿å­˜æ•°æ®
        for i in range(5):
            try:
                title = jsonDecode["data"][i]["target"]["title"]
                link = 'https://www.zhihu.com/question/' + str(jsonDecode["data"][i]["target"]["id"])
                cover = jsonDecode["data"][i]["children"][0]["thumbnail"]
                content = jsonDecode["data"][i]["target"]["excerpt"]
                result = []
                result.append(('çŸ¥ä¹', str(i + 1), title, link, cover, content))
                # print(result)
                inesrt_re = "insert ignore into huinews (source,rank,title,link,cover,content) values (%s, %s, %s, %s, %s, %s)"
                cursor = db.cursor()
                cursor.executemany(inesrt_re, result)
                db.commit()
            except Exception as e:
                db.rollback()
                print(str(e))
                break
        rssItems=db_query("çŸ¥ä¹")
        makeRss("çŸ¥ä¹çƒ­æ¦œ", url, "çŸ¥ä¹çƒ­é—¨æ’è¡Œæ¦œ", rssItems)
    except Exception as e:
        print(sys._getframe().f_code.co_name+"é‡‡é›†é”™è¯¯ï¼Œè¯·åŠæ—¶æ›´æ–°è§„åˆ™ï¼" + str(e))

#------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

def db_query(name):
    # æŸ¥è¯¢æ•°æ®
    sql = "SELECT * FROM huinews \
        WHERE TO_DAYS( news_time ) = TO_DAYS(NOW()) \
        AND source = %s" % ("'" + name + "'")
    try:
        # æ‰§è¡ŒSQLè¯­å¥
        cursor.execute(sql)
        # è·å–æ‰€æœ‰è®°å½•åˆ—è¡¨
        results = cursor.fetchall()
        rssItems=[]
        for row in results:
            rank = row[2]
            hot = ' ' + str(row[5]) if row[5] else ''
            img = '<img src="' + str(row[6]) + '" referrerpolicy="no-referrer"> ' if row[6] else ''
            label = ' ã€' + str(row[7]) + 'ã€' if row[7] else ''
            content = ' ' + str(row[8]) if row[8] else ''
            
            rssItem=PyRSS2Gen.RSSItem(
            title=row[3] if rank>3 else row[3] + 'ğŸ”¥',
            link=row[4],
            description=img + str(rank) + label + hot + content,
            pubDate=row[10]
            )
            rssItems.append(rssItem)
        return rssItems
    except Exception as e:
        print("æŸ¥è¯¢æ•°æ®å¤±è´¥ï¼" + str(e))

def makeRss(title, url, description, rssItems):
	rss = PyRSS2Gen.RSS2(
	title = title, 
	link = url,
	description = description, 
	lastBuildDate = datetime.datetime.now(),
	items = rssItems)
	rss.write_xml(open('Z:\\' + title + '_Rss.xml', "w",encoding='utf-8'),encoding='utf-8') 
	pass

# æ‰“å¼€æ•°æ®åº“è¿æ¥
def db_connect():
    config = ConfigParser()
    config.read('pymysql.ini')
    host = config.get('mysql','host')
    port = config.getint('mysql','port')
    user = config.get('mysql','user')
    password = config.get('mysql','password')
    database = config.get('mysql','database')
    db = pymysql.connect(host=host,
                         port=port,
                         user=user,
                         password=password,
                         database=database)
    return db

# å­—ç¬¦æ›¿æ¢åŠ å¯†(é»˜è®¤ä¸ºå¤§å°å†™åè½¬),ä¿®æ”¹æ­¤å¤„é¡ºåºå’Œæ·»åŠ æ•°å­—æ›¿æ¢å¯å®ç°ä¸åŒå¯†ç åŠ å¯†(å¹¶åŒæ—¶ä¿®æ”¹get/index.phpå†…å¯†ç )
def multiple_replace(text):
    dic = {"a": "A", "b": "B", "c": "C", "d": "D", "e": "E", "f": "F", "g": "G", "h": "H", "i": "I", "j": "J", "k": "K", "l": "L", "m": "M", "n": "N", "o": "O", "p": "P", "q": "Q", "r": "R", "s": "S", "t": "T", "u": "U", "v": "V", "w": "W", "x": "X", "y": "Y", "z": "Z",
           "A": "a", "B": "b", "C": "c", "D": "d", "E": "e", "F": "f", "G": "g", "H": "h", "I": "i", "J": "j", "K": "k", "L": "l", "M": "m", "N": "n", "O": "o", "P": "p", "Q": "q", "R": "r", "S": "s", "T": "t", "U": "u", "V": "v", "W": "w", "X": "x", "Y": "y", "Z": "z"}
    pattern = "|".join(map(re.escape, list(dic.keys())))
    return re.sub(pattern, lambda m: dic[m.group()], text)

def single_run(db):
    # å•çº¿ç¨‹è¿è¡Œ
    print("å•çº¿ç¨‹é‡‡é›†å¼€å§‹", time.strftime("%Y-%m-%d %H:%M:%S", time.localtime()))
    t1 = time.time()
    parse_weibo(db)
    parse_baidu(db)
    parse_zhihu(db)
    print("å•çº¿ç¨‹é‡‡é›†å®Œæˆ", time.strftime("%Y-%m-%d %H:%M:%S", time.localtime()))
    print("è€—æ—¶:", time.time() - t1)


def multi_run(db):
    # å¤šçº¿ç¨‹æŠ“å–
    print("å¤šçº¿ç¨‹é‡‡é›†å¼€å§‹", time.strftime("%Y-%m-%d %H:%M:%S", time.localtime()))
    t1 = time.time()
    threads = []
    ts1 = Thread(target=parse_weibo, args=(db,))
    ts2 = Thread(target=parse_baidu, args=(db,))
    ts3 = Thread(target=parse_zhihu, args=(db,))
    threads.append(ts1)
    threads.append(ts2)
    threads.append(ts3)
    for t in threads:
        t.start()
    for t in threads:
        t.join()
    print("å¤šçº¿ç¨‹é‡‡é›†å®Œæˆ", time.strftime("%Y-%m-%d %H:%M:%S", time.localtime()))
    print("è€—æ—¶:", time.time() - t1)


if __name__ == "__main__":
    db = db_connect()
    # ä½¿ç”¨cursor()æ–¹æ³•è·å–æ“ä½œæ¸¸æ ‡
    cursor = db.cursor()

    if thread == 'single':
        # while True:
        single_run(db)
    if thread == 'multi':
        # while True:
        multi_run(db)

    # å…³é—­æ•°æ®åº“è¿æ¥
    db.close()
